{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "468fdb53",
   "metadata": {},
   "source": [
    "# Week 1 - Tasks\n",
    "\n",
    "- **Data Source:** `yfinance`\n",
    "- **Assets:** `AAPL`, `MSFT`, `GOOG`, `AMZN`, `TSLA` (and `NVDA` for Task 5)\n",
    "- **Timeframes:**\n",
    "  * **Long Term:** `start=\"2015-01-01\", end=\"2024-01-01\"`\n",
    "  * **Medium Term:** `start=\"2020-01-01\", end=\"2024-01-01\"` (Includes COVID crash)\n",
    "\n",
    "The goal for this week is to gain familiarity with financial data, analyze common trends, learn standard library functions, and touch upon the underlying theory."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4c2f621",
   "metadata": {},
   "source": [
    "## Task 1 - Setup\n",
    "* Fetch **Long Term** historical data for the 5 assets.\n",
    "* Extract the `Adjusted Close` values.\n",
    "    * *Note: Check for missing values or empty rows and handle them (drop or fill).*\n",
    "* Use `df.describe()` to extract key summary statistics.\n",
    "* Extract the **Medium Term** data as well for later tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33a3ddb3",
   "metadata": {},
   "source": [
    "## Task 2 - Basic Trends\n",
    "* Select **one asset** and using the **Medium Term** data, compute:\n",
    "    * **Returns:** 1-day, 5-day, and 20-day simple returns.\n",
    "    * **Log Returns:** 1-day, 5-day, and 20-day log returns.\n",
    "    * **Volatility:** 5-day, 20-day, and 60-day rolling standard deviation (volatility) of the log returns.\n",
    "* **Plotting:**\n",
    "    * Plot the price and the 20-day moving average on one chart.\n",
    "    * Plot the 1-day log returns on a separate chart.\n",
    "    * Plot the rolling volatilities on a third chart.\n",
    "    * *Analysis:* What trends do you observe? Does high volatility correlate with price drops?\n",
    "\n",
    "* **Bonus (Long Term Data):**\n",
    "    * Create a scatter plot of `|Daily Return|` vs `Volume`. Is there a relationship?\n",
    "    * Group returns and volatility by **Month** (e.g., all Januaries, all Februaries) and plot the averages. Is there a \"seasonal\" effect?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a252aa33",
   "metadata": {},
   "source": [
    "## Task 3 - Stationarity\n",
    "* Select **one asset** (Long Term).\n",
    "* Compute the **Rolling Mean** and **Rolling Standard Deviation** of log returns with window sizes `20, 60, 120`.\n",
    "* Plot them and visually inspect.\n",
    "    * Does the mean stay constant? (Stationary mean)\n",
    "    * Does the variance stay constant? (Stationary variance)\n",
    "* Run an **Augmented Dickey-Fuller (ADF) Test** on the log return series.\n",
    "    * Library: `from statsmodels.tsa.stattools import adfuller`\n",
    "    * *Goal:* Interpret the p-value. The Null Hypothesis ($H_0$) is that the series is non-stationary (has a unit root). If p-value < 0.05, we reject $H_0$.\n",
    "    * For learning about hypothesis testing and p-value you can refer to CS215 slides or other standard resources mentioned in READMEs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "380ab7ab",
   "metadata": {},
   "source": [
    "## Task 4 - Volatility Regimes\n",
    "We try to study the trend in volatility more deeply. From the ACF/PACF plot we know that volatility tends to cluster that is the market is either in a high volatility state (greater daily fluctuations) or low volatility state (stable prices, quiet markets).\n",
    "\n",
    "Formally we can treat volatility as a *conditional standard deviation of returns*, conditioned on the history observed so far. We *cannot* predict *true* volatility for a given day based on the single return value, hence we try to estimate it using the past information. For this we look at two indicators of volatility:\n",
    "\n",
    "1.  **Rolling Window Volatility:** Simple Moving Average (SMA) of standard deviation.\n",
    "2.  **EWMA Volatility:** Exponentially Weighted Moving Average. This gives more weight to recent events. It is given by $\\sigma_t^2 = (1-\\lambda)r_t^2 + \\lambda \\sigma_{t-1}^2$.\n",
    "\n",
    "**Steps:**\n",
    "* Pick an asset and use data covering the **Feb-Mar 2020 COVID crash**.\n",
    "* Compute two volatility estimates on the Log Returns:\n",
    "    1.  **Rolling 20-day Volatility:** Standard deviation over a 20-day window.\n",
    "    2.  **EWMA Volatility (RiskMetrics):** Use a decay factor $\\lambda = 0.94$.\n",
    "        * *Hint:* In pandas `df.ewm()`, the parameter `alpha` corresponds to $1 - \\lambda$. So, use `alpha=0.06`.\n",
    "* **Analysis:**\n",
    "    * Plot both estimates on the same chart.\n",
    "    * Which is smoother?\n",
    "    * Which estimator reacts faster to the sudden crash in March 2020?\n",
    "    * Which one would you prefer for risk management?\n",
    "* **Regime Detection:** Compute the 60th percentile of your EWMA volatility series. Shade the regions on the plot where volatility exceeds this level.\n",
    "\n",
    "* **Bonus:** A good volatility model \"standardizes\" the returns well. Calculate $z_t = r_t / \\hat{\\sigma}_t$. If the model is good, $z_t$ should have $Var \\approx 1$. Check the variance of $z_t$ and plot its histogram."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c881c67c",
   "metadata": {},
   "source": [
    "## Task 5 - Time Horizons and the \"Normal\" Illusion\n",
    "Short-term markets are noisy and dangerous (fat tails), while long-term data looks smoother. We can prove this statistically using **Skew** and **Kurtosis**.\n",
    "\n",
    "**Theory:**\n",
    "* **Skewness:** Measures asymmetry. (Negative skew = frequent small gains, few extreme losses).\n",
    "* **Kurtosis:** Measures \"tailedness\". (High kurtosis = frequent extreme events/crashes).\n",
    "* **Normal Distribution:** Skew $\\approx 0$, Kurtosis $\\approx 3$ (or Excess Kurtosis $\\approx 0$).\n",
    "\n",
    "**Steps:**\n",
    "1.  Take your **Long Term** data for one asset (e.g., NVDA or TSLA).\n",
    "2.  Resample the prices to get **Weekly** and **Monthly** closes.\n",
    "    * Use `df['Adj Close'].resample('W').last()` and `...resample('M').last()`.\n",
    "3.  Compute Log Returns for all three series: Daily, Weekly, Monthly.\n",
    "4.  **The Test:**\n",
    "    * Calculate **Skew** and **Kurtosis** for each of the three return series.\n",
    "    * *Question:* How do these values change as the time horizon increases? Do they get closer to 0 and 3?\n",
    "5.  **Visualization:**\n",
    "    * Plot the **Histograms** of the Daily returns vs. Monthly returns on the same plot.\n",
    "    * *Tip:* You will need to standardize them (subtract mean, divide by std dev) to overlay them meaningfully.\n",
    "    * *Observation:* Look at the tails. Which one has \"fatter\" tails (more extreme outliers)?\n",
    "\n",
    "**Key Takeaway:**\n",
    "Daily returns often violate the \"Normal Distribution\" assumption used in many financial models. Long-term returns fit it better. This is called *Aggregational Gaussianity*.\n",
    "\n",
    "**Bonus:** This is a direct application of a simple yet well-known result in asymptotic statistics. Can you find out what it is and state how it explains this observation?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "713820d4",
   "metadata": {},
   "source": [
    "## Task 6 - Smart investing\n",
    "Calculate how many **RTX 4090s** (approx. price $1,600$) you could afford *today* if you had invested **$1,000** in NVIDIA on the day you were born."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
